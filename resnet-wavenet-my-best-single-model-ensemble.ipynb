{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036935,
     "end_time": "2021-01-27T18:21:26.894910",
     "exception": false,
     "start_time": "2021-01-27T18:21:26.857975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hi to all!!!\n",
    "# Earlier I published a notebook that allowed me to work in both google colab and kaggle notebook (https://www.kaggle.com/aikhmelnytskyy/resnet-tpu-on-colab-and-kaggle).\n",
    "# Now I want to publish my best model for today.\n",
    "# The model is a pure experiment. \n",
    "# I was wondering what would happen if I used Wavenet (https://www.kaggle.com/nxrprime/wavenet-with-shifted-rfc-proba-and-cbr).\n",
    "# As a result, I mixed Resnet and Wavenet and got this result.\n",
    "# The idea of ​​my experiment is that I use the Resnet model (or any other model) in the first stage, in the next stage I pass n layers of this model to the wavenet, and I concatenate the results. \n",
    "# If you like my notebooks, don't forget to upvote!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034224,
     "end_time": "2021-01-27T18:21:26.963489",
     "exception": false,
     "start_time": "2021-01-27T18:21:26.929265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I used these notebooks as a basis: https://www.kaggle.com/mekhdigakhramanian/rfcx-resnet50-tpu https://www.kaggle.com/khoongweihao/resnet34-more-augmentations-mixup-tta-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:27.039159Z",
     "iopub.status.busy": "2021-01-27T18:21:27.038379Z",
     "iopub.status.idle": "2021-01-27T18:21:36.441992Z",
     "shell.execute_reply": "2021-01-27T18:21:36.441340Z"
    },
    "papermill": {
     "duration": 9.44343,
     "end_time": "2021-01-27T18:21:36.442110",
     "exception": false,
     "start_time": "2021-01-27T18:21:26.998680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install image-classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037458,
     "end_time": "2021-01-27T18:21:36.517596",
     "exception": false,
     "start_time": "2021-01-27T18:21:36.480138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:36.602333Z",
     "iopub.status.busy": "2021-01-27T18:21:36.601686Z",
     "iopub.status.idle": "2021-01-27T18:21:45.046180Z",
     "shell.execute_reply": "2021-01-27T18:21:45.045586Z"
    },
    "papermill": {
     "duration": 8.490963,
     "end_time": "2021-01-27T18:21:45.046288",
     "exception": false,
     "start_time": "2021-01-27T18:21:36.555325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio\n",
    "\n",
    "from classification_models.keras import Classifiers\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:45.129530Z",
     "iopub.status.busy": "2021-01-27T18:21:45.128882Z",
     "iopub.status.idle": "2021-01-27T18:21:45.130935Z",
     "shell.execute_reply": "2021-01-27T18:21:45.131420Z"
    },
    "papermill": {
     "duration": 0.046934,
     "end_time": "2021-01-27T18:21:45.131577",
     "exception": false,
     "start_time": "2021-01-27T18:21:45.084643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03753,
     "end_time": "2021-01-27T18:21:45.207891",
     "exception": false,
     "start_time": "2021-01-27T18:21:45.170361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:45.287093Z",
     "iopub.status.busy": "2021-01-27T18:21:45.286346Z",
     "iopub.status.idle": "2021-01-27T18:21:45.289700Z",
     "shell.execute_reply": "2021-01-27T18:21:45.290206Z"
    },
    "papermill": {
     "duration": 0.04445,
     "end_time": "2021-01-27T18:21:45.290382",
     "exception": false,
     "start_time": "2021-01-27T18:21:45.245932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from https://github.com/qubvel/classification_models\n",
    "ResNet34, preprocess_input = Classifiers.get('resnet34')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:45.372190Z",
     "iopub.status.busy": "2021-01-27T18:21:45.371517Z",
     "iopub.status.idle": "2021-01-27T18:21:45.379891Z",
     "shell.execute_reply": "2021-01-27T18:21:45.380400Z"
    },
    "papermill": {
     "duration": 0.051707,
     "end_time": "2021-01-27T18:21:45.380552",
     "exception": false,
     "start_time": "2021-01-27T18:21:45.328845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'parse_params': {\n",
    "        'cut_time': 10,\n",
    "    },\n",
    "    'data_params': {\n",
    "        'sample_time': 6, # assert 60 % sample_time == 0\n",
    "        'spec_fmax': 24000.0,\n",
    "        'spec_fmin': 40.0,\n",
    "        'spec_mel': 384,#284, \n",
    "        'mel_power': 2,\n",
    "        'img_shape': (384, 784)#(284, 512)\n",
    "    },\n",
    "    'model_params': {\n",
    "        'batchsize_per_tpu': 16,\n",
    "        'iteration_per_epoch': 64,\n",
    "        'epoch': 25, \n",
    "        'arch': ResNet34,\n",
    "        'arch_preprocess': preprocess_input,\n",
    "        'freeze_to': 0,  # Freeze to backbone.layers[:freeze_to]. If None, all layers in the backbone will be freezed.\n",
    "        'loss': {\n",
    "            'fn': tfa.losses.SigmoidFocalCrossEntropy,\n",
    "            'params': {},\n",
    "        },\n",
    "        'optim': {\n",
    "            'fn': tfa.optimizers.RectifiedAdam,\n",
    "            'params': {'lr': 2e-3, 'total_steps': 18*64, 'warmup_proportion': 0.3, 'min_lr': 1e-6},\n",
    "        },\n",
    "        'mixup': True # False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:45.460672Z",
     "iopub.status.busy": "2021-01-27T18:21:45.460028Z",
     "iopub.status.idle": "2021-01-27T18:21:49.575888Z",
     "shell.execute_reply": "2021-01-27T18:21:49.574901Z"
    },
    "papermill": {
     "duration": 4.157075,
     "end_time": "2021-01-27T18:21:49.576042",
     "exception": false,
     "start_time": "2021-01-27T18:21:45.418967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:49.657312Z",
     "iopub.status.busy": "2021-01-27T18:21:49.656641Z",
     "iopub.status.idle": "2021-01-27T18:21:50.211379Z",
     "shell.execute_reply": "2021-01-27T18:21:50.211945Z"
    },
    "papermill": {
     "duration": 0.597449,
     "end_time": "2021-01-27T18:21:50.212097",
     "exception": false,
     "start_time": "2021-01-27T18:21:49.614648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path('rfcx-species-audio-detection')\n",
    "\n",
    "TRAIN_TFREC = GCS_DS_PATH + \"/tfrecords/train\"\n",
    "TEST_TFREC = GCS_DS_PATH + \"/tfrecords/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:50.293608Z",
     "iopub.status.busy": "2021-01-27T18:21:50.292910Z",
     "iopub.status.idle": "2021-01-27T18:21:50.299227Z",
     "shell.execute_reply": "2021-01-27T18:21:50.299856Z"
    },
    "papermill": {
     "duration": 0.048638,
     "end_time": "2021-01-27T18:21:50.300011",
     "exception": false,
     "start_time": "2021-01-27T18:21:50.251373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CUT = cfg['parse_params']['cut_time']\n",
    "SR = 48000     # all wave's sample rate may be 48k\n",
    "\n",
    "TIME = cfg['data_params']['sample_time']\n",
    "\n",
    "FMAX = cfg['data_params']['spec_fmax']\n",
    "FMIN = cfg['data_params']['spec_fmin']\n",
    "N_MEL = cfg['data_params']['spec_mel']\n",
    "\n",
    "HEIGHT, WIDTH = cfg['data_params']['img_shape']\n",
    "\n",
    "CLASS_N = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038895,
     "end_time": "2021-01-27T18:21:50.378010",
     "exception": false,
     "start_time": "2021-01-27T18:21:50.339115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Explore the tfrecords, Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:50.459429Z",
     "iopub.status.busy": "2021-01-27T18:21:50.458772Z",
     "iopub.status.idle": "2021-01-27T18:21:50.481151Z",
     "shell.execute_reply": "2021-01-27T18:21:50.480589Z"
    },
    "papermill": {
     "duration": 0.064202,
     "end_time": "2021-01-27T18:21:50.481308",
     "exception": false,
     "start_time": "2021-01-27T18:21:50.417106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_dataset = tf.data.TFRecordDataset([TRAIN_TFREC + '/00-148.tfrec'])\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040101,
     "end_time": "2021-01-27T18:21:50.561794",
     "exception": false,
     "start_time": "2021-01-27T18:21:50.521693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## parse tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:50.668357Z",
     "iopub.status.busy": "2021-01-27T18:21:50.657692Z",
     "iopub.status.idle": "2021-01-27T18:21:51.638872Z",
     "shell.execute_reply": "2021-01-27T18:21:51.639433Z"
    },
    "papermill": {
     "duration": 1.036487,
     "end_time": "2021-01-27T18:21:51.639596",
     "exception": false,
     "start_time": "2021-01-27T18:21:50.603109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'recording_id': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'audio_wav': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'label_info': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "}\n",
    "parse_dtype = {\n",
    "    'audio_wav': tf.float32,\n",
    "    'recording_id': tf.string,\n",
    "    'species_id': tf.int32,\n",
    "    'songtype_id': tf.int32,\n",
    "    't_min': tf.float32,\n",
    "    'f_min': tf.float32,\n",
    "    't_max': tf.float32,\n",
    "    'f_max':tf.float32,\n",
    "    'is_tp': tf.int32\n",
    "}\n",
    "\n",
    "@tf.function\n",
    "def _parse_function(example_proto):\n",
    "    sample = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    wav, _ = tf.audio.decode_wav(sample['audio_wav'], desired_channels=1) # mono\n",
    "    label_info = tf.strings.split(sample['label_info'], sep='\"')[1]\n",
    "    labels = tf.strings.split(label_info, sep=';')\n",
    "    \n",
    "    @tf.function\n",
    "    def _cut_audio(label):\n",
    "        items = tf.strings.split(label, sep=',')\n",
    "        spid = tf.squeeze(tf.strings.to_number(items[0], tf.int32))\n",
    "        soid = tf.squeeze(tf.strings.to_number(items[1], tf.int32))\n",
    "        tmin = tf.squeeze(tf.strings.to_number(items[2]))\n",
    "        fmin = tf.squeeze(tf.strings.to_number(items[3]))\n",
    "        tmax = tf.squeeze(tf.strings.to_number(items[4]))\n",
    "        fmax = tf.squeeze(tf.strings.to_number(items[5]))\n",
    "        tp = tf.squeeze(tf.strings.to_number(items[6], tf.int32))\n",
    "\n",
    "        tmax_s = tmax * tf.cast(SR, tf.float32)\n",
    "        tmin_s = tmin * tf.cast(SR, tf.float32)\n",
    "        cut_s = tf.cast(CUT * SR, tf.float32)\n",
    "        all_s = tf.cast(60 * SR, tf.float32)\n",
    "        tsize_s = tmax_s - tmin_s\n",
    "        cut_min = tf.cast(\n",
    "            tf.maximum(0.0, \n",
    "                tf.minimum(tmin_s - (cut_s - tsize_s) / 2,\n",
    "                           tf.minimum(tmax_s + (cut_s - tsize_s) / 2, all_s) - cut_s)\n",
    "            ), tf.int32\n",
    "        )\n",
    "        cut_max = cut_min + CUT * SR\n",
    "        \n",
    "        _sample = {\n",
    "            'audio_wav': tf.reshape(wav[cut_min:cut_max], [CUT*SR]),\n",
    "            'recording_id': sample['recording_id'],\n",
    "            'species_id': spid,\n",
    "            'songtype_id': soid,\n",
    "            't_min': tmin - tf.cast(cut_min, tf.float32)/tf.cast(SR, tf.float32),\n",
    "            'f_min': fmin,\n",
    "            't_max': tmax - tf.cast(cut_min, tf.float32)/tf.cast(SR, tf.float32),\n",
    "            'f_max': fmax,\n",
    "            'is_tp': tp\n",
    "        }\n",
    "        return _sample\n",
    "    \n",
    "    samples = tf.map_fn(_cut_audio, labels, dtype=parse_dtype)\n",
    "    return samples\n",
    "\n",
    "parsed_dataset = raw_dataset.map(_parse_function).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:51.752538Z",
     "iopub.status.busy": "2021-01-27T18:21:51.751444Z",
     "iopub.status.idle": "2021-01-27T18:21:51.753908Z",
     "shell.execute_reply": "2021-01-27T18:21:51.754503Z"
    },
    "papermill": {
     "duration": 0.061312,
     "end_time": "2021-01-27T18:21:51.754641",
     "exception": false,
     "start_time": "2021-01-27T18:21:51.693329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _cut_wav(x):\n",
    "    # random cut in training\n",
    "    cut_min = tf.random.uniform([], maxval=(CUT-TIME)*SR, dtype=tf.int32)\n",
    "    cut_max = cut_min + TIME * SR\n",
    "    cutwave = tf.reshape(x['audio_wav'][cut_min:cut_max], [TIME*SR])\n",
    "    y = {}\n",
    "    y.update(x)\n",
    "    y['audio_wav'] = cutwave\n",
    "    y['t_min'] = tf.maximum(0.0, x['t_min'] - tf.cast(cut_min, tf.float32) / SR)\n",
    "    y['t_max'] = tf.maximum(0.0, x['t_max'] - tf.cast(cut_min, tf.float32) / SR)\n",
    "    return y\n",
    "    \n",
    "@tf.function\n",
    "def _cut_wav_val(x):\n",
    "    # center crop in validation\n",
    "    cut_min = (CUT-TIME)*SR // 2\n",
    "    cut_max = cut_min + TIME * SR\n",
    "    cutwave = tf.reshape(x['audio_wav'][cut_min:cut_max], [TIME*SR])\n",
    "    y = {}\n",
    "    y.update(x)\n",
    "    y['audio_wav'] = cutwave\n",
    "    y['t_min'] = tf.maximum(0.0, x['t_min'] - tf.cast(cut_min, tf.float32) / SR)\n",
    "    y['t_max'] = tf.maximum(0.0, x['t_max'] - tf.cast(cut_min, tf.float32) / SR)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:51.838611Z",
     "iopub.status.busy": "2021-01-27T18:21:51.837616Z",
     "iopub.status.idle": "2021-01-27T18:21:51.842237Z",
     "shell.execute_reply": "2021-01-27T18:21:51.842793Z"
    },
    "papermill": {
     "duration": 0.048562,
     "end_time": "2021-01-27T18:21:51.842936",
     "exception": false,
     "start_time": "2021-01-27T18:21:51.794374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _filtTP(x):\n",
    "    return x['is_tp'] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:51.927792Z",
     "iopub.status.busy": "2021-01-27T18:21:51.926810Z",
     "iopub.status.idle": "2021-01-27T18:21:58.608006Z",
     "shell.execute_reply": "2021-01-27T18:21:58.607290Z"
    },
    "papermill": {
     "duration": 6.724777,
     "end_time": "2021-01-27T18:21:58.608134",
     "exception": false,
     "start_time": "2021-01-27T18:21:51.883357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_wav(sample, ax):\n",
    "    wav = sample[\"audio_wav\"].numpy()\n",
    "    rate = SR\n",
    "    ax.plot(np.arange(len(wav)) / rate, wav)\n",
    "    ax.set_title(\n",
    "        sample[\"recording_id\"].numpy().decode()\n",
    "        + (\"/%d\" % sample[\"species_id\"])\n",
    "        + (\"TP\" if sample[\"is_tp\"] else \"FP\"))\n",
    "\n",
    "    return Audio((wav * 2**15).astype(np.int16), rate=rate)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "show_wav(next(iter(parsed_dataset)), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064825,
     "end_time": "2021-01-27T18:21:58.740122",
     "exception": false,
     "start_time": "2021-01-27T18:21:58.675297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## create mel-spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:58.879264Z",
     "iopub.status.busy": "2021-01-27T18:21:58.878477Z",
     "iopub.status.idle": "2021-01-27T18:21:59.618689Z",
     "shell.execute_reply": "2021-01-27T18:21:59.618075Z"
    },
    "papermill": {
     "duration": 0.815404,
     "end_time": "2021-01-27T18:21:59.618822",
     "exception": false,
     "start_time": "2021-01-27T18:21:58.803418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _wav_to_spec(x):\n",
    "    mel_power = cfg['data_params']['mel_power']\n",
    "    \n",
    "    stfts = tf.signal.stft(x[\"audio_wav\"], frame_length=2048, frame_step=512, fft_length=2048)\n",
    "    spectrograms = tf.abs(stfts) ** mel_power\n",
    "\n",
    "    # Warp the linear scale spectrograms into the mel-scale.\n",
    "    num_spectrogram_bins = stfts.shape[-1]\n",
    "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = FMIN, FMAX, N_MEL\n",
    "    \n",
    "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
    "      num_mel_bins, num_spectrogram_bins, SR, lower_edge_hertz,\n",
    "      upper_edge_hertz)\n",
    "    mel_spectrograms = tf.tensordot(\n",
    "      spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n",
    "      linear_to_mel_weight_matrix.shape[-1:]))\n",
    "\n",
    "    # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "    log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "\n",
    "    y = {\n",
    "        'audio_spec': tf.transpose(log_mel_spectrograms), # (num_mel_bins, frames)\n",
    "    }\n",
    "    y.update(x)\n",
    "    return y\n",
    "\n",
    "spec_dataset = parsed_dataset.filter(_filtTP).map(_cut_wav).map(_wav_to_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:21:59.755176Z",
     "iopub.status.busy": "2021-01-27T18:21:59.754302Z",
     "iopub.status.idle": "2021-01-27T18:22:00.717978Z",
     "shell.execute_reply": "2021-01-27T18:22:00.717282Z"
    },
    "papermill": {
     "duration": 1.034482,
     "end_time": "2021-01-27T18:22:00.718092",
     "exception": false,
     "start_time": "2021-01-27T18:21:59.683610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "for i, s in enumerate(spec_dataset.take(3)):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    plt.imshow(s['audio_spec'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:00.867260Z",
     "iopub.status.busy": "2021-01-27T18:22:00.866554Z",
     "iopub.status.idle": "2021-01-27T18:22:00.872321Z",
     "shell.execute_reply": "2021-01-27T18:22:00.871682Z"
    },
    "papermill": {
     "duration": 0.084867,
     "end_time": "2021-01-27T18:22:00.872437",
     "exception": false,
     "start_time": "2021-01-27T18:22:00.787570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def show_spectrogram(sample, ax, showlabel=False):\n",
    "    S_dB = sample[\"audio_spec\"].numpy()\n",
    "    img = librosa.display.specshow(S_dB, x_axis='time',\n",
    "                             y_axis='mel', sr=SR,\n",
    "                             fmax=FMAX, fmin=FMIN, ax=ax, cmap='magma')\n",
    "    ax.set(title=f'Mel-frequency spectrogram of {sample[\"recording_id\"].numpy().decode()}')\n",
    "    sid, fmin, fmax, tmin, tmax, istp = (\n",
    "            sample[\"species_id\"], sample[\"f_min\"], sample[\"f_max\"], sample[\"t_min\"], sample[\"t_max\"], sample[\"is_tp\"])\n",
    "    ec = '#00ff00' if istp == 1 else '#0000ff'\n",
    "    ax.add_patch(\n",
    "        patches.Rectangle(xy=(tmin, fmin), width=tmax-tmin, height=fmax-fmin, ec=ec, fill=False)\n",
    "    )\n",
    "\n",
    "    if showlabel:\n",
    "        ax.text(tmin, fmax, \n",
    "        f\"{sid.numpy().item()} {'tp' if istp == 1 else 'fp'}\",\n",
    "        horizontalalignment='left', verticalalignment='bottom', color=ec, fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:01.018576Z",
     "iopub.status.busy": "2021-01-27T18:22:01.014054Z",
     "iopub.status.idle": "2021-01-27T18:22:01.829496Z",
     "shell.execute_reply": "2021-01-27T18:22:01.830025Z"
    },
    "papermill": {
     "duration": 0.890436,
     "end_time": "2021-01-27T18:22:01.830169",
     "exception": false,
     "start_time": "2021-01-27T18:22:00.939733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,3))\n",
    "show_spectrogram(next(iter(spec_dataset)), ax, showlabel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:01.994113Z",
     "iopub.status.busy": "2021-01-27T18:22:01.989676Z",
     "iopub.status.idle": "2021-01-27T18:22:03.053185Z",
     "shell.execute_reply": "2021-01-27T18:22:03.053714Z"
    },
    "papermill": {
     "duration": 1.146849,
     "end_time": "2021-01-27T18:22:03.053856",
     "exception": false,
     "start_time": "2021-01-27T18:22:01.907007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in validation, annotations will come to the center\n",
    "fig, ax = plt.subplots(figsize=(15,3))\n",
    "show_spectrogram(next(iter(parsed_dataset.filter(_filtTP).map(_cut_wav_val).map(_wav_to_spec))), ax, showlabel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:03.225198Z",
     "iopub.status.busy": "2021-01-27T18:22:03.224356Z",
     "iopub.status.idle": "2021-01-27T18:22:06.081645Z",
     "shell.execute_reply": "2021-01-27T18:22:06.082192Z"
    },
    "papermill": {
     "duration": 2.946361,
     "end_time": "2021-01-27T18:22:06.082342",
     "exception": false,
     "start_time": "2021-01-27T18:22:03.135981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for sample in spec_dataset.take(5):\n",
    "    fig, ax = plt.subplots(figsize=(15,3))\n",
    "    show_spectrogram(sample, ax, showlabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.114007,
     "end_time": "2021-01-27T18:22:06.318185",
     "exception": false,
     "start_time": "2021-01-27T18:22:06.204178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:06.552676Z",
     "iopub.status.busy": "2021-01-27T18:22:06.551396Z",
     "iopub.status.idle": "2021-01-27T18:22:06.671292Z",
     "shell.execute_reply": "2021-01-27T18:22:06.670565Z"
    },
    "papermill": {
     "duration": 0.24083,
     "end_time": "2021-01-27T18:22:06.671424",
     "exception": false,
     "start_time": "2021-01-27T18:22:06.430594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _create_annot(x):\n",
    "    targ = tf.one_hot(x[\"species_id\"], CLASS_N, on_value=x[\"is_tp\"], off_value=0)\n",
    "    \n",
    "    return {\n",
    "        'input': x[\"audio_spec\"],\n",
    "        'target': tf.cast(targ, tf.float32)\n",
    "    }\n",
    "\n",
    "annot_dataset = spec_dataset.map(_create_annot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.112099,
     "end_time": "2021-01-27T18:22:06.896036",
     "exception": false,
     "start_time": "2021-01-27T18:22:06.783937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing and data augmentation\n",
    "\n",
    "In training, I use\n",
    "\n",
    "* gaussian noise\n",
    "* random flip left & right (NEW)\n",
    "* random brightness\n",
    "* specaugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:07.147739Z",
     "iopub.status.busy": "2021-01-27T18:22:07.146944Z",
     "iopub.status.idle": "2021-01-27T18:22:07.153651Z",
     "shell.execute_reply": "2021-01-27T18:22:07.152924Z"
    },
    "papermill": {
     "duration": 0.145622,
     "end_time": "2021-01-27T18:22:07.153777",
     "exception": false,
     "start_time": "2021-01-27T18:22:07.008155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _preprocess_img(x, training=False, test=False):\n",
    "    image = tf.expand_dims(x, axis=-1)\n",
    "    image = tf.image.resize(image, [HEIGHT, WIDTH])\n",
    "    image = tf.image.per_image_standardization(image)\n",
    "    \n",
    "    @tf.function\n",
    "    def _specaugment(image):\n",
    "        ERASE_TIME = 50\n",
    "        ERASE_MEL = 16\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        xoff = tf.random.uniform([2], minval=ERASE_TIME//2, maxval=WIDTH-ERASE_TIME//2, dtype=tf.int32)\n",
    "        xsize = tf.random.uniform([2], minval=ERASE_TIME//2, maxval=ERASE_TIME, dtype=tf.int32)\n",
    "        yoff = tf.random.uniform([2], minval=ERASE_MEL//2, maxval=HEIGHT-ERASE_MEL//2, dtype=tf.int32)\n",
    "        ysize = tf.random.uniform([2], minval=ERASE_MEL//2, maxval=ERASE_MEL, dtype=tf.int32)\n",
    "        image = tfa.image.cutout(image, [HEIGHT, xsize[0]], offset=[HEIGHT//2, xoff[0]])\n",
    "        image = tfa.image.cutout(image, [HEIGHT, xsize[1]], offset=[HEIGHT//2, xoff[1]])\n",
    "        image = tfa.image.cutout(image, [ysize[0], WIDTH], offset=[yoff[0], WIDTH//2])\n",
    "        image = tfa.image.cutout(image, [ysize[1], WIDTH], offset=[yoff[1], WIDTH//2])\n",
    "        image = tf.squeeze(image, axis=0)\n",
    "        return image\n",
    "    \n",
    "    if training:\n",
    "        # gaussian\n",
    "        gau = tf.keras.layers.GaussianNoise(0.3)\n",
    "        image = tf.cond(tf.random.uniform([]) < 0.5, lambda: gau(image, training=True), lambda: image)\n",
    "        # brightness\n",
    "        image = tf.image.random_brightness(image, 0.2)\n",
    "        # random left right flip (NEW)\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        # specaugment\n",
    "        #image = tf.cond(tf.random.uniform([]) < 0.5, lambda: _specaugment(image), lambda: image)\n",
    "        \n",
    "    if test:\n",
    "        # Insert augmentations for TTA here\n",
    "        #image = tf.cond(tf.random.uniform([]) < 0.5, lambda: _specaugment(image), lambda: image)\n",
    "        pass\n",
    "        \n",
    "    image = (image - tf.reduce_min(image)) / (tf.reduce_max(image) - tf.reduce_min(image)) * 255.0 # rescale to [0, 255]\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    #image =tf.reshape(image, [-1])\n",
    "    image = cfg['model_params']['arch_preprocess'](image)\n",
    "\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def _preprocess(x):\n",
    "    image = _preprocess_img(x['input'], training=True, test=False)\n",
    "    return (image, x[\"target\"])\n",
    "\n",
    "@tf.function\n",
    "def _preprocess_val(x):\n",
    "    image = _preprocess_img(x['input'], training=False, test=False)\n",
    "    return (image, x[\"target\"])\n",
    "\n",
    "@tf.function\n",
    "def _preprocess_test(x):\n",
    "    image = _preprocess_img(x['audio_spec'], training=False, test=True)\n",
    "    return (image, x[\"recording_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:07.387102Z",
     "iopub.status.busy": "2021-01-27T18:22:07.386021Z",
     "iopub.status.idle": "2021-01-27T18:22:07.390530Z",
     "shell.execute_reply": "2021-01-27T18:22:07.391015Z"
    },
    "papermill": {
     "duration": 0.123938,
     "end_time": "2021-01-27T18:22:07.391169",
     "exception": false,
     "start_time": "2021-01-27T18:22:07.267231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "for inp, targ in annot_dataset.map(_preprocess).take(2):\n",
    "    plt.imshow(inp.numpy()[:,:,0])\n",
    "    t = targ.numpy()\n",
    "    if t.sum() == 0:\n",
    "        plt.title(f'FP')\n",
    "    else:\n",
    "        plt.title(f'{t.nonzero()[0]}')\n",
    "    plt.colorbar()\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.116309,
     "end_time": "2021-01-27T18:22:07.622398",
     "exception": false,
     "start_time": "2021-01-27T18:22:07.506089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:07.869933Z",
     "iopub.status.busy": "2021-01-27T18:22:07.864361Z",
     "iopub.status.idle": "2021-01-27T18:22:14.751942Z",
     "shell.execute_reply": "2021-01-27T18:22:14.752492Z"
    },
    "papermill": {
     "duration": 7.01669,
     "end_time": "2021-01-27T18:22:14.752641",
     "exception": false,
     "start_time": "2021-01-27T18:22:07.735951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import losses, models, optimizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_model():\n",
    "    #with strategy.scope():\n",
    "    #backbone = cfg['model_params']['arch'](include_top=False, weights='imagenet')\n",
    "    \n",
    "    def Classifier(shape_):\n",
    "\n",
    "        backbone = cfg['model_params']['arch']((shape_), include_top=False, weights='imagenet')\n",
    "    \n",
    "    \n",
    "        \n",
    "        def cbr(x, out_layer, kernel, stride, dilation):\n",
    "            x = Conv2D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "            return x\n",
    "\n",
    "        def wave_block(x, filters, kernel_size, n):\n",
    "            dilation_rates = [2**i for i in range(n)]\n",
    "            x = Conv2D(filters = filters,\n",
    "                       kernel_size = 1,\n",
    "                       padding = 'same')(x)\n",
    "            res_x = x\n",
    "            for dilation_rate in dilation_rates:\n",
    "                tanh_out = Conv2D(filters = filters,\n",
    "                                  kernel_size = kernel_size,\n",
    "                                  padding = 'same', \n",
    "                                  activation = 'tanh', \n",
    "                                  dilation_rate = dilation_rate)(x)\n",
    "                sigm_out = Conv2D(filters = filters,\n",
    "                                  kernel_size = kernel_size,\n",
    "                                  padding = 'same',\n",
    "                                  activation = 'sigmoid', \n",
    "                                  dilation_rate = dilation_rate)(x)\n",
    "                x = Multiply()([tanh_out, sigm_out])\n",
    "                x = Conv2D(filters = filters,\n",
    "                           kernel_size = 1,\n",
    "                           padding = 'same')(x)\n",
    "                res_x = Add()([res_x, x])\n",
    "            return res_x\n",
    "\n",
    "        \n",
    "        #out1\n",
    "        def wavenet(layer):\n",
    "          \n",
    "          x = cbr(layer, 192, 7, 1, 1)\n",
    "          x = BatchNormalization()(x)\n",
    "          x = wave_block(x, 192, 3, 1)\n",
    "          x = cbr(x, 96, 7, 1, 1)\n",
    "          x = BatchNormalization()(x)\n",
    "          x = wave_block(x, 96, 3, 1)\n",
    "          x = cbr(x, 48, 5, 1, 1)\n",
    "          x = BatchNormalization()(x)\n",
    "          x = wave_block(x, 48, 3, 1)  \n",
    "          return x\n",
    "\n",
    "        def wavenet1(layer):\n",
    "          \n",
    "          x = cbr(layer, 4, 7, 1, 1)\n",
    "          x = BatchNormalization()(x)\n",
    "          x = wave_block(x, 3, 3, 1)\n",
    "          x = cbr(x, 3, 7, 1, 1)\n",
    "          x = BatchNormalization()(x)\n",
    "          x = wave_block(x, 16, 3, 1)\n",
    "          x = cbr(x, 3, 5, 1, 1)\n",
    "          return x\n",
    "        #x = BatchNormalization()(x)\n",
    "        \n",
    "        x0 = backbone#model\n",
    "        print('1')\n",
    "        #backbone.summary()\n",
    "        x1 = tf.keras.layers.GlobalAveragePooling2D()(x0.layers[-1].output)  #-3,-7,-9,-15  for EF5    \n",
    "        #x2 = tf.keras.layers.GlobalAveragePooling2D()(x0.layers[-3].output) # 803,799,797,791 for EF7\n",
    "        x3 = tf.keras.layers.GlobalAveragePooling2D()(x0.layers[-7].output)\n",
    "        #x4 = tf.keras.layers.GlobalAveragePooling2D()(x0.layers[-12].output)\n",
    "        x5 = tf.keras.layers.GlobalAveragePooling2D()(x0.layers[-18].output)\n",
    "        print('2')\n",
    "        x1=wavenet(x0.layers[-1].output)\n",
    "        x3=wavenet(x0.layers[-7].output)\n",
    "        x5=wavenet(x0.layers[-18].output)\n",
    "\n",
    "        x1 = tf.keras.layers.GlobalAveragePooling2D()(x1)\n",
    "        x3 = tf.keras.layers.GlobalAveragePooling2D()(x3)\n",
    "        x5 = tf.keras.layers.GlobalAveragePooling2D()(x5)\n",
    "       \n",
    "        \n",
    "        \n",
    "        print('4')\n",
    "        #x =  tf.concat([x1,x2,x3,x4,x5],axis = 1)\n",
    "       \n",
    "        x =  tf.concat([x1,x3,x5],axis = 1)\n",
    "      \n",
    "        x = tf.keras.layers.Dropout(0.7)(x)\n",
    "        x = tf.keras.layers.Dense(192)(x)\n",
    "        #x =  tf.keras.layers.BatchNormalization()(x)          \n",
    "        x = tf.keras.layers.Dropout(0.4)(x)\n",
    "        #x =  margin([x , label])\n",
    "        \n",
    "        output = tf.keras.layers.Softmax(dtype='float32')(x)\n",
    "        output =tf.keras.layers.Dense(CLASS_N)(x)\n",
    "        print('5')\n",
    "        model = tf.keras.models.Model(inputs = x0.input, outputs = output)\n",
    "        #model.compile(optimizer=optimizer, loss=loss_fn, metrics=[LWLRAP(CLASS_N)])\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        return model\n",
    "    return Classifier([HEIGHT,WIDTH,3])\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:15.017259Z",
     "iopub.status.busy": "2021-01-27T18:22:15.016504Z",
     "iopub.status.idle": "2021-01-27T18:22:15.019725Z",
     "shell.execute_reply": "2021-01-27T18:22:15.019050Z"
    },
    "papermill": {
     "duration": 0.137952,
     "end_time": "2021-01-27T18:22:15.019846",
     "exception": false,
     "start_time": "2021-01-27T18:22:14.881894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def _mixup(inp, targ):\n",
    "    indice = tf.range(len(inp))\n",
    "    indice = tf.random.shuffle(indice)\n",
    "    sinp = tf.gather(inp, indice, axis=0)\n",
    "    starg = tf.gather(targ, indice, axis=0)\n",
    "    \n",
    "    alpha = 0.2\n",
    "    t = tf.compat.v1.distributions.Beta(alpha, alpha).sample([len(inp)])\n",
    "    tx = tf.reshape(t, [-1, 1, 1, 1])\n",
    "    ty = tf.reshape(t, [-1, 1])\n",
    "    x = inp * tx + sinp * (1-tx)\n",
    "    y = targ * ty + starg * (1-ty)\n",
    "#     y = tf.minimum(targ + starg, 1.0) # for multi-label???\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:15.363113Z",
     "iopub.status.busy": "2021-01-27T18:22:15.361889Z",
     "iopub.status.idle": "2021-01-27T18:22:15.410818Z",
     "shell.execute_reply": "2021-01-27T18:22:15.411385Z"
    },
    "papermill": {
     "duration": 0.267403,
     "end_time": "2021-01-27T18:22:15.411567",
     "exception": false,
     "start_time": "2021-01-27T18:22:15.144164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfrecs = sorted(tf.io.gfile.glob(TRAIN_TFREC + '/*.tfrec'))\n",
    "parsed_trainval = (tf.data.TFRecordDataset(tfrecs, num_parallel_reads=AUTOTUNE)\n",
    "                    .map(_parse_function, num_parallel_calls=AUTOTUNE).unbatch()\n",
    "                    .filter(_filtTP).enumerate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.123269,
     "end_time": "2021-01-27T18:22:15.658700",
     "exception": false,
     "start_time": "2021-01-27T18:22:15.535431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Stratified 5-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:22:15.917297Z",
     "iopub.status.busy": "2021-01-27T18:22:15.915170Z",
     "iopub.status.idle": "2021-01-27T18:24:03.280214Z",
     "shell.execute_reply": "2021-01-27T18:24:03.280767Z"
    },
    "papermill": {
     "duration": 107.498883,
     "end_time": "2021-01-27T18:24:03.280949",
     "exception": false,
     "start_time": "2021-01-27T18:22:15.782066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "spid = []\n",
    "recid = []\n",
    "\n",
    "for i, sample in tqdm(parsed_trainval.prefetch(AUTOTUNE)):\n",
    "    indices.append(i.numpy())\n",
    "    spid.append(sample['species_id'].numpy())\n",
    "    recid.append(sample['recording_id'].numpy().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:03.665217Z",
     "iopub.status.busy": "2021-01-27T18:24:03.664072Z",
     "iopub.status.idle": "2021-01-27T18:24:03.677122Z",
     "shell.execute_reply": "2021-01-27T18:24:03.677738Z"
    },
    "papermill": {
     "duration": 0.221062,
     "end_time": "2021-01-27T18:24:03.677990",
     "exception": false,
     "start_time": "2021-01-27T18:24:03.456928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = pd.DataFrame({'indices': indices, 'species_id': spid, 'recording_id': recid})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:04.048292Z",
     "iopub.status.busy": "2021-01-27T18:24:04.047591Z",
     "iopub.status.idle": "2021-01-27T18:24:04.273178Z",
     "shell.execute_reply": "2021-01-27T18:24:04.273659Z"
    },
    "papermill": {
     "duration": 0.413148,
     "end_time": "2021-01-27T18:24:04.273818",
     "exception": false,
     "start_time": "2021-01-27T18:24:03.860670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=True)\n",
    "splits = list(skf.split(table.index, table.species_id))\n",
    "\n",
    "plt.hist([table.loc[splits[0][0], 'species_id'], table.loc[splits[0][1], 'species_id']], bins=CLASS_N,stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:04.635222Z",
     "iopub.status.busy": "2021-01-27T18:24:04.634338Z",
     "iopub.status.idle": "2021-01-27T18:24:04.638110Z",
     "shell.execute_reply": "2021-01-27T18:24:04.637558Z"
    },
    "papermill": {
     "duration": 0.18857,
     "end_time": "2021-01-27T18:24:04.638225",
     "exception": false,
     "start_time": "2021-01-27T18:24:04.449655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_idx_filter(indice):\n",
    "    @tf.function\n",
    "    def _filt(i, x):\n",
    "        return tf.reduce_any(indice == i)\n",
    "    return _filt\n",
    "\n",
    "@tf.function\n",
    "def _remove_idx(i, x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.177789,
     "end_time": "2021-01-27T18:24:04.991634",
     "exception": false,
     "start_time": "2021-01-27T18:24:04.813845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Other setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:05.364059Z",
     "iopub.status.busy": "2021-01-27T18:24:05.363354Z",
     "iopub.status.idle": "2021-01-27T18:24:05.366685Z",
     "shell.execute_reply": "2021-01-27T18:24:05.366036Z"
    },
    "papermill": {
     "duration": 0.195223,
     "end_time": "2021-01-27T18:24:05.366805",
     "exception": false,
     "start_time": "2021-01-27T18:24:05.171582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_train_dataset(batchsize, train_idx):\n",
    "    global parsed_trainval\n",
    "    parsed_train = (parsed_trainval\n",
    "                    .filter(create_idx_filter(train_idx))\n",
    "                    .map(_remove_idx))\n",
    "    \n",
    "    dataset = (parsed_train.cache()\n",
    "        .shuffle(len(train_idx))\n",
    "        .repeat()\n",
    "        .map(_cut_wav, num_parallel_calls=AUTOTUNE)\n",
    "        .map(_wav_to_spec, num_parallel_calls=AUTOTUNE)\n",
    "        .map(_create_annot, num_parallel_calls=AUTOTUNE)\n",
    "        .map(_preprocess, num_parallel_calls=AUTOTUNE)\n",
    "        .batch(batchsize))\n",
    "\n",
    "    if cfg['model_params']['mixup']:\n",
    "        dataset = (dataset.map(_mixup, num_parallel_calls=AUTOTUNE)\n",
    "                    .prefetch(AUTOTUNE))\n",
    "    else:\n",
    "        dataset = dataset.prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def create_val_dataset(batchsize, val_idx):\n",
    "    global parsed_trainval\n",
    "    parsed_val = (parsed_trainval\n",
    "                  .filter(create_idx_filter(val_idx))\n",
    "                  .map(_remove_idx))\n",
    "\n",
    "    vdataset = (parsed_val\n",
    "        .map(_cut_wav_val, num_parallel_calls=AUTOTUNE)\n",
    "        .map(_wav_to_spec, num_parallel_calls=AUTOTUNE)\n",
    "        .map(_create_annot, num_parallel_calls=AUTOTUNE)\n",
    "        .map(_preprocess_val, num_parallel_calls=AUTOTUNE)\n",
    "        .batch(8*strategy.num_replicas_in_sync)\n",
    "        .cache())\n",
    "    return vdataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.178119,
     "end_time": "2021-01-27T18:24:05.720221",
     "exception": false,
     "start_time": "2021-01-27T18:24:05.542102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:06.096747Z",
     "iopub.status.busy": "2021-01-27T18:24:06.095954Z",
     "iopub.status.idle": "2021-01-27T18:24:06.099380Z",
     "shell.execute_reply": "2021-01-27T18:24:06.098834Z"
    },
    "papermill": {
     "duration": 0.201673,
     "end_time": "2021-01-27T18:24:06.099508",
     "exception": false,
     "start_time": "2021-01-27T18:24:05.897835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from https://www.kaggle.com/carlthome/l-lrap-metric-for-tf-keras\n",
    "@tf.function\n",
    "def _one_sample_positive_class_precisions(example):\n",
    "    y_true, y_pred = example\n",
    "\n",
    "    retrieved_classes = tf.argsort(y_pred, direction='DESCENDING')\n",
    "    class_rankings = tf.argsort(retrieved_classes)\n",
    "    retrieved_class_true = tf.gather(y_true, retrieved_classes)\n",
    "    retrieved_cumulative_hits = tf.math.cumsum(tf.cast(retrieved_class_true, tf.float32))\n",
    "\n",
    "    idx = tf.where(y_true)[:, 0]\n",
    "    i = tf.boolean_mask(class_rankings, y_true)\n",
    "    r = tf.gather(retrieved_cumulative_hits, i)\n",
    "    c = 1 + tf.cast(i, tf.float32)\n",
    "    precisions = r / c\n",
    "\n",
    "    dense = tf.scatter_nd(idx[:, None], precisions, [y_pred.shape[0]])\n",
    "    return dense\n",
    "\n",
    "class LWLRAP(tf.keras.metrics.Metric):\n",
    "    def __init__(self, num_classes, name='lwlrap'):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self._precisions = self.add_weight(\n",
    "            name='per_class_cumulative_precision',\n",
    "            shape=[num_classes],\n",
    "            initializer='zeros',\n",
    "        )\n",
    "\n",
    "        self._counts = self.add_weight(\n",
    "            name='per_class_cumulative_count',\n",
    "            shape=[num_classes],\n",
    "            initializer='zeros',\n",
    "        )\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        precisions = tf.map_fn(\n",
    "            fn=_one_sample_positive_class_precisions,\n",
    "            elems=(y_true, y_pred),\n",
    "            dtype=(tf.float32),\n",
    "        )\n",
    "\n",
    "        increments = tf.cast(precisions > 0, tf.float32)\n",
    "        total_increments = tf.reduce_sum(increments, axis=0)\n",
    "        total_precisions = tf.reduce_sum(precisions, axis=0)\n",
    "\n",
    "        self._precisions.assign_add(total_precisions)\n",
    "        self._counts.assign_add(total_increments)        \n",
    "\n",
    "    def result(self):\n",
    "        per_class_lwlrap = self._precisions / tf.maximum(self._counts, 1.0)\n",
    "        per_class_weight = self._counts / tf.reduce_sum(self._counts)\n",
    "        overall_lwlrap = tf.reduce_sum(per_class_lwlrap * per_class_weight)\n",
    "        return overall_lwlrap\n",
    "\n",
    "    def reset_states(self):\n",
    "        self._precisions.assign(self._precisions * 0)\n",
    "        self._counts.assign(self._counts * 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.177209,
     "end_time": "2021-01-27T18:24:06.453163",
     "exception": false,
     "start_time": "2021-01-27T18:24:06.275954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testset and Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:06.827521Z",
     "iopub.status.busy": "2021-01-27T18:24:06.826687Z",
     "iopub.status.idle": "2021-01-27T18:24:06.829657Z",
     "shell.execute_reply": "2021-01-27T18:24:06.829130Z"
    },
    "papermill": {
     "duration": 0.200095,
     "end_time": "2021-01-27T18:24:06.829774",
     "exception": false,
     "start_time": "2021-01-27T18:24:06.629679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _parse_function_test(example_proto):\n",
    "    sample = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    wav, _ = tf.audio.decode_wav(sample['audio_wav'], desired_channels=1) # mono\n",
    "    \n",
    "    @tf.function\n",
    "    def _cut_audio(i):\n",
    "        _sample = {\n",
    "            'audio_wav': tf.reshape(wav[i*SR*TIME:(i+1)*SR*TIME], [SR*TIME]),\n",
    "            'recording_id': sample['recording_id']\n",
    "        }\n",
    "        return _sample\n",
    "\n",
    "    return tf.map_fn(_cut_audio, tf.range(60//TIME), dtype={\n",
    "        'audio_wav': tf.float32,\n",
    "        'recording_id': tf.string\n",
    "    })\n",
    "\n",
    "def inference(model):\n",
    "    tdataset = (tf.data.TFRecordDataset(tf.io.gfile.glob(TEST_TFREC + '/*.tfrec'), num_parallel_reads=AUTOTUNE)\n",
    "        .map(_parse_function_test, num_parallel_calls=AUTOTUNE).unbatch()\n",
    "        .map(_wav_to_spec, num_parallel_calls=AUTOTUNE)\n",
    "        .map(_preprocess_test, num_parallel_calls=AUTOTUNE)\n",
    "        .batch(128*(60//TIME)).prefetch(AUTOTUNE))\n",
    "    \n",
    "    rec_ids = []\n",
    "    probs = []\n",
    "    for inp, rec_id in tqdm(tdataset):\n",
    "        with strategy.scope():\n",
    "            pred = model.predict_on_batch(tf.reshape(inp, [-1, HEIGHT, WIDTH, 3]))\n",
    "            prob = tf.sigmoid(pred)\n",
    "            prob = tf.reduce_max(tf.reshape(prob, [-1, 60//TIME, CLASS_N]), axis=1)\n",
    "\n",
    "        rec_id_stack = tf.reshape(rec_id, [-1, 60//TIME])\n",
    "        for rec in rec_id.numpy():\n",
    "            assert len(np.unique(rec)) == 1\n",
    "        rec_ids.append(rec_id_stack.numpy()[:,0])\n",
    "        probs.append(prob.numpy())\n",
    "        \n",
    "    crec_ids = np.concatenate(rec_ids)\n",
    "    cprobs = np.concatenate(probs)\n",
    "    \n",
    "    sub = pd.DataFrame({\n",
    "        'recording_id': list(map(lambda x: x.decode(), crec_ids.tolist())),\n",
    "        **{f's{i}': cprobs[:,i] for i in range(CLASS_N)}\n",
    "    })\n",
    "    sub = sub.sort_values('recording_id')\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:07.191099Z",
     "iopub.status.busy": "2021-01-27T18:24:07.189951Z",
     "iopub.status.idle": "2021-01-27T18:24:07.193247Z",
     "shell.execute_reply": "2021-01-27T18:24:07.192638Z"
    },
    "papermill": {
     "duration": 0.188471,
     "end_time": "2021-01-27T18:24:07.193371",
     "exception": false,
     "start_time": "2021-01-27T18:24:07.004900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_history(history, name):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.title(\"loss\")\n",
    "    # plt.yscale('log')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history[\"lwlrap\"])\n",
    "    plt.plot(history.history[\"val_lwlrap\"])\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.title(\"metric\")\n",
    "\n",
    "    plt.savefig(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.17671,
     "end_time": "2021-01-27T18:24:07.546544",
     "exception": false,
     "start_time": "2021-01-27T18:24:07.369834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Now start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:07.942001Z",
     "iopub.status.busy": "2021-01-27T18:24:07.920490Z",
     "iopub.status.idle": "2021-01-27T18:24:07.944972Z",
     "shell.execute_reply": "2021-01-27T18:24:07.944248Z"
    },
    "papermill": {
     "duration": 0.213169,
     "end_time": "2021-01-27T18:24:07.945091",
     "exception": false,
     "start_time": "2021-01-27T18:24:07.731922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RMAC:\n",
    "    def __init__(self, shape, levels=3, power=None, overlap=0.4, norm_fm=False, sum_fm=True, verbose=False):\n",
    "        self.shape = shape\n",
    "        self.sum_fm = sum_fm\n",
    "        self.norm = norm_fm\n",
    "        self.power = power\n",
    " \n",
    "        # ported from Giorgios' Matlab code\n",
    "        steps = np.asarray([2, 3, 4, 5, 6, 7])\n",
    "        B, H, W, D = shape\n",
    "        w = min([W, H])\n",
    "        w2 = w // 2 - 1\n",
    "        b = np.asarray((max(H, W) - w)) / (steps - 1);\n",
    "        idx = np.argmin(np.abs(((w**2 - w*b)/(w**2))-overlap))\n",
    " \n",
    "        Wd = 0\n",
    "        Hd = 0\n",
    "        if H < W:\n",
    "            Wd = idx + 1\n",
    "        elif H > W:\n",
    "            Hd = idx + 1\n",
    " \n",
    "        self.regions = []\n",
    "        for l in range(levels):\n",
    " \n",
    "            wl = int(2 * w/(l+2));\n",
    "            wl2 = int(wl / 2 - 1);\n",
    " \n",
    "            b = 0 if not (l + Wd) else ((W - wl) / (l + Wd))\n",
    "            cenW = np.asarray(np.floor(wl2 + np.asarray(range(l+Wd+1)) * b), dtype=np.int32) - wl2\n",
    "            b = 0 if not (l + Hd) else ((H - wl) / (l + Hd))\n",
    "            cenH = np.asarray(np.floor(wl2 + np.asarray(range(l+Hd+1)) * b), dtype=np.int32) - wl2\n",
    " \n",
    "            for i in cenH:\n",
    "                for j in cenW:\n",
    "                    if i >= W or j >= H:\n",
    "                        continue\n",
    "                    ie = i+wl\n",
    "                    je = j+wl\n",
    "                    if ie >= W:\n",
    "                        ie = W\n",
    "                    if je >= H:\n",
    "                        je = H\n",
    "                    if ie - i < 1 or je - j < 1:\n",
    "                        continue\n",
    "                    self.regions.append((i,j,ie,je))\n",
    " \n",
    "        if verbose:\n",
    "            print('RMAC regions = %s' % self.regions)\n",
    " \n",
    "    def rmac(self, x):\n",
    "        y = []\n",
    "        for r in self.regions:\n",
    "            x_sliced = x[:, r[1]:r[3], r[0]:r[2], :]\n",
    "            if self.power is None:\n",
    "                x_maxed = tf.reduce_max(x_sliced, axis=(1,2))\n",
    "            else:\n",
    "                x_maxed = tf.reduce_mean((x_sliced ** self.power), axis=(2,3)) ** (1.0 / self.power)\n",
    "                x_maxed = tf.pow(tf.reduce_mean((tf.pow(x_sliced, self.power)), axis=(2,3)),(1.0 / self.power))\n",
    "            y.append(x_maxed)\n",
    " \n",
    "        y = tf.stack(y, axis=0)\n",
    "        y = tf.transpose(y, [1,0,2])\n",
    " \n",
    "        if self.norm:\n",
    "            y = tf.math.l2_normalize(y, 2)\n",
    " \n",
    " \n",
    "        if self.sum_fm:\n",
    "            y = tf.reduce_mean(y, axis=(1))\n",
    " \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:08.319257Z",
     "iopub.status.busy": "2021-01-27T18:24:08.318279Z",
     "iopub.status.idle": "2021-01-27T18:24:08.321728Z",
     "shell.execute_reply": "2021-01-27T18:24:08.321205Z"
    },
    "papermill": {
     "duration": 0.198967,
     "end_time": "2021-01-27T18:24:08.321846",
     "exception": false,
     "start_time": "2021-01-27T18:24:08.122879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_inference(splits, split_id):\n",
    "    print(\"split_id\", split_id)\n",
    "    batchsize = cfg['model_params']['batchsize_per_tpu'] * strategy.num_replicas_in_sync\n",
    "    print(\"batchsize\", batchsize)\n",
    "    loss_fn = cfg['model_params']['loss']['fn'](from_logits=True, **cfg['model_params']['loss']['params'])\n",
    "    \n",
    "    idx_train_tf = tf.constant(splits[split_id][0])\n",
    "    idx_val_tf = tf.constant(splits[split_id][1])\n",
    "\n",
    "    dataset = create_train_dataset(batchsize, idx_train_tf)\n",
    "    vdataset = create_val_dataset(batchsize, idx_val_tf)\n",
    "    \n",
    "    optimizer = cfg['model_params']['optim']['fn'](**cfg['model_params']['optim']['params'])\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = create_model()\n",
    "        model.compile(optimizer=optimizer, loss=loss_fn, metrics=[LWLRAP(CLASS_N)])\n",
    "        #model.summary()\n",
    "        \n",
    "       \n",
    "    \n",
    "    history = model.fit(dataset,\n",
    "                        steps_per_epoch=cfg['model_params']['iteration_per_epoch'],\n",
    "                        epochs=cfg['model_params']['epoch'],\n",
    "                        validation_data=vdataset,\n",
    "                        callbacks=[\n",
    "                            tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                                'val_lwlrap', patience=10\n",
    "                            ),\n",
    "                            tf.keras.callbacks.ModelCheckpoint(\n",
    "                                filepath='model_best_%d.h5' % split_id,\n",
    "                                save_weights_only=True,\n",
    "                                monitor='val_lwlrap',\n",
    "                                mode='max',\n",
    "                                save_best_only=True),\n",
    "                        ])\n",
    "    plot_history(history, 'history_%d.png' % split_id)\n",
    "    \n",
    "    ### inference ###\n",
    "    model.load_weights('model_best_%d.h5' % split_id)\n",
    "    \n",
    "    return inference(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.300122,
     "end_time": "2021-01-27T18:24:08.848553",
     "exception": false,
     "start_time": "2021-01-27T18:24:08.548431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### # The whole training process in version 1 of this notebook.\n",
    "\n",
    "# To save time, I did not restart training for version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:09.207317Z",
     "iopub.status.busy": "2021-01-27T18:24:09.206514Z",
     "iopub.status.idle": "2021-01-27T18:24:09.210759Z",
     "shell.execute_reply": "2021-01-27T18:24:09.210109Z"
    },
    "papermill": {
     "duration": 0.184966,
     "end_time": "2021-01-27T18:24:09.210870",
     "exception": false,
     "start_time": "2021-01-27T18:24:09.025904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "''' To train the medals, delete this line!!!!\n",
    "\n",
    "# train and inference\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "# N-fold ensemble\n",
    "sub = sum(\n",
    "    map(\n",
    "        lambda i: train_and_inference(splits, i).set_index('recording_id'),\n",
    "        range(len(splits))\n",
    "    )\n",
    ").reset_index()\n",
    "#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.176424,
     "end_time": "2021-01-27T18:24:09.566933",
     "exception": false,
     "start_time": "2021-01-27T18:24:09.390509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Now let's make an ensemble with public models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:09.934418Z",
     "iopub.status.busy": "2021-01-27T18:24:09.933739Z",
     "iopub.status.idle": "2021-01-27T18:24:09.960146Z",
     "shell.execute_reply": "2021-01-27T18:24:09.960741Z"
    },
    "papermill": {
     "duration": 0.215735,
     "end_time": "2021-01-27T18:24:09.960896",
     "exception": false,
     "start_time": "2021-01-27T18:24:09.745161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/resnetwavenet851/submission.csv')# my model score 0.851 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:10.323994Z",
     "iopub.status.busy": "2021-01-27T18:24:10.322986Z",
     "iopub.status.idle": "2021-01-27T18:24:10.360078Z",
     "shell.execute_reply": "2021-01-27T18:24:10.360617Z"
    },
    "papermill": {
     "duration": 0.220224,
     "end_time": "2021-01-27T18:24:10.360782",
     "exception": false,
     "start_time": "2021-01-27T18:24:10.140558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub2 = pd.read_csv('../input/automl-inference-audio-detection-soliset/submission.csv')# public model score 0.876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:10.719129Z",
     "iopub.status.busy": "2021-01-27T18:24:10.718090Z",
     "iopub.status.idle": "2021-01-27T18:24:10.758843Z",
     "shell.execute_reply": "2021-01-27T18:24:10.757255Z"
    },
    "papermill": {
     "duration": 0.221367,
     "end_time": "2021-01-27T18:24:10.758980",
     "exception": false,
     "start_time": "2021-01-27T18:24:10.537613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.iloc[:,1:]=sub.iloc[:,1:]*0.30+sub2.iloc[:,1:]*0.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:11.127352Z",
     "iopub.status.busy": "2021-01-27T18:24:11.126527Z",
     "iopub.status.idle": "2021-01-27T18:24:11.205862Z",
     "shell.execute_reply": "2021-01-27T18:24:11.205171Z"
    },
    "papermill": {
     "duration": 0.268021,
     "end_time": "2021-01-27T18:24:11.205976",
     "exception": false,
     "start_time": "2021-01-27T18:24:10.937955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-27T18:24:11.570001Z",
     "iopub.status.busy": "2021-01-27T18:24:11.569296Z",
     "iopub.status.idle": "2021-01-27T18:24:11.743295Z",
     "shell.execute_reply": "2021-01-27T18:24:11.742618Z"
    },
    "papermill": {
     "duration": 0.35843,
     "end_time": "2021-01-27T18:24:11.743421",
     "exception": false,
     "start_time": "2021-01-27T18:24:11.384991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.192758,
     "end_time": "2021-01-27T18:24:12.129961",
     "exception": false,
     "start_time": "2021-01-27T18:24:11.937203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# If you have any questions then ask. It would be interesting to hear ideas for improving this model. Good luck to all!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rain_forest_gpu",
   "language": "python",
   "name": "rain_forest_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "duration": 170.2684,
   "end_time": "2021-01-27T18:24:12.435415",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-27T18:21:22.167015",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
